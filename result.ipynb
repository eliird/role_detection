{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "win_len_2.5_model_f_xf_inp_mode_diso_carlos_new_data: 65.71% ± 5.53% | Train size: 21064.0 | Test size: 2347.0 | Input shape: (41880, 300)\n",
      "win_len_2.0_model_f_xf_inp_mode_diso_carlos_new_data: 64.43% ± 6.11% | Train size: 28119.7 | Test size: 3066.8 | Input shape: (55783, 240)\n",
      "win_len_1.5_model_f_xf_inp_mode_diso_carlos_new_data: 63.19% ± 5.48% | Train size: 41531.35 | Test size: 4461.65 | Input shape: (82196, 180)\n"
     ]
    }
   ],
   "source": [
    "# Glob all results file\n",
    "result_filepaths = list(Path('.').glob('cross_val_results/cross_validation_win_len_*_model_f_xf_inp_mode_diso_carlos_new_data.tar'))\n",
    "# result_filepaths += list(Path('.').glob('cross_val_results/cross_validation_win_len_*_model_f_xf_inp_mode_diso_carlos_new_data.tar'))\n",
    "\n",
    "run_names, means, stds, train_n_samples, test_n_samples, input_shapes = [], [], [], [], [], []\n",
    "for filepath in result_filepaths:\n",
    "    # Load data\n",
    "    with open(str(filepath), 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    # Take max accuracy for each fold\n",
    "    max_accs = [max(v['acc']) for v in data.values()]\n",
    "\n",
    "    run_names.append(filepath.stem.replace('cross_validation_', ''))\n",
    "    means.append(np.mean(max_accs))\n",
    "    stds.append(np.std(max_accs))\n",
    "\n",
    "    # Input shape\n",
    "    input_shapes.append(data[0]['train_size'])\n",
    "\n",
    "    # Get number of samples\n",
    "    train_sizes = [v['train_size'] for v in data.values()]\n",
    "    train_n_samples.append(np.mean(train_sizes))\n",
    "\n",
    "    test_sizes = [v['test_size'] for v in data.values()]\n",
    "    test_n_samples.append(np.mean(test_sizes))\n",
    "\n",
    "# Sort by mean accuracy\n",
    "sort_idx = np.argsort(means)[::-1]\n",
    "run_names = [run_names[i] for i in sort_idx]\n",
    "means = [means[i] for i in sort_idx]\n",
    "stds = [stds[i] for i in sort_idx]\n",
    "train_sizes = [train_n_samples[i] for i in sort_idx]\n",
    "test_sizes = [test_n_samples[i] for i in sort_idx]\n",
    "input_shapes = [input_shapes[i] for i in sort_idx]\n",
    "\n",
    "# Print results\n",
    "for run_name, mean, std, train_size, test_size, in_shape in zip(run_names, means, stds, train_sizes, test_sizes, input_shapes):\n",
    "    print(f'{run_name}: {100*mean:.2f}% ± {100*std:.2f}% | Train size: {train_size} | Test size: {test_size} | Input shape: {in_shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "role-det",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
